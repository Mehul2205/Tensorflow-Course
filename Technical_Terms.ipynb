{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Technical_Terms.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "aKnArNgAGmnb",
        "ARxOog7fGuvX",
        "mtleda4vHj_m",
        "gFAnv_HgIKER",
        "0YiPXjltI_Bw"
      ],
      "authorship_tag": "ABX9TyMUjMZ6aHqgm+cRW1cU0jz5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKnArNgAGmnb",
        "colab_type": "text"
      },
      "source": [
        "# Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARxOog7fGuvX",
        "colab_type": "text"
      },
      "source": [
        "## Multi-Class Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbloaC6nGxF3",
        "colab_type": "text"
      },
      "source": [
        "One-of-many classification. Each sample can belong to ONE of C classes. The CNN will have C output neurons that can be gathered in a vector s (Scores). The target (ground truth) vector t will be a one-hot vector with a positive class and C−1 negative classes.\n",
        "\n",
        "This task is treated as a single classification problem of samples in one of \n",
        "C classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mtleda4vHj_m"
      },
      "source": [
        "## Multi-Label Classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPn3c2bKH3jE",
        "colab_type": "text"
      },
      "source": [
        "Each sample can belong to more than one class. The CNN will have as well \n",
        "C\n",
        " output neurons. The target vector \n",
        "t\n",
        " can have more than a positive class, so it will be a vector of 0s and 1s with \n",
        "C\n",
        " dimensionality.\n",
        "This task is treated as \n",
        "C\n",
        " different binary \n",
        "(\n",
        "C\n",
        "′\n",
        "=\n",
        "2\n",
        ",\n",
        "t\n",
        "′\n",
        "=\n",
        "0\n",
        " or \n",
        "t\n",
        "′\n",
        "=\n",
        "1\n",
        ")\n",
        " and independent classification problems, where each output neuron decides if a sample belongs to a class or not.\n",
        "\n",
        "![alt text](https://gombru.github.io/assets/cross_entropy_loss/multiclass_multilabel.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFAnv_HgIKER",
        "colab_type": "text"
      },
      "source": [
        "# Output Activation Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5hRqDBRISxJ",
        "colab_type": "text"
      },
      "source": [
        "## Sigmoid\n",
        "It squashes a vector in the range (0, 1). It is applied independently to each element of \n",
        "s\n",
        " \n",
        "si\n",
        ". It’s also called logistic function.\n",
        "![alt text](https://gombru.github.io/assets/cross_entropy_loss/sigmoid.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1A08QcGI2ao",
        "colab_type": "text"
      },
      "source": [
        "## Softmax\n",
        "Softmax it’s a function, not a loss. It squashes a vector in the range (0, 1) and all the resulting elements add up to 1. It is applied to the output scores \n",
        "s\n",
        ". As elements represent a class, they can be interpreted as class probabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YiPXjltI_Bw",
        "colab_type": "text"
      },
      "source": [
        "# Losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64wFNkwMJCVI",
        "colab_type": "text"
      },
      "source": [
        "Caffe: SoftmaxWithLoss Layer. Is limited to multi-class classification.\n",
        "\n",
        "Pytorch: CrossEntropyLoss. Is limited to multi-class classification.\n",
        "\n",
        "TensorFlow: softmax_cross_entropy. Is limited to multi-class classification."
      ]
    }
  ]
}